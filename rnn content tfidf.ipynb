{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('train/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>Darrell Lucus</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
       "      <td>Daniel J. Flynn</td>\n",
       "      <td>Ever get the feeling your life circles the rou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Why the Truth Might Get You Fired</td>\n",
       "      <td>Consortiumnews.com</td>\n",
       "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
       "      <td>Jessica Purkiss</td>\n",
       "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
       "      <td>Howard Portnoy</td>\n",
       "      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title              author  \\\n",
       "0   0  House Dem Aide: We Didn’t Even See Comey’s Let...       Darrell Lucus   \n",
       "1   1  FLYNN: Hillary Clinton, Big Woman on Campus - ...     Daniel J. Flynn   \n",
       "2   2                  Why the Truth Might Get You Fired  Consortiumnews.com   \n",
       "3   3  15 Civilians Killed In Single US Airstrike Hav...     Jessica Purkiss   \n",
       "4   4  Iranian woman jailed for fictional unpublished...      Howard Portnoy   \n",
       "\n",
       "                                                text  label  \n",
       "0  House Dem Aide: We Didn’t Even See Comey’s Let...      1  \n",
       "1  Ever get the feeling your life circles the rou...      0  \n",
       "2  Why the Truth Might Get You Fired October 29, ...      1  \n",
       "3  Videos 15 Civilians Killed In Single US Airstr...      1  \n",
       "4  Print \\nAn Iranian woman has been sentenced to...      1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop('label',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages=X.copy()\n",
    "messages.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: 18284 / 18285\r"
     ]
    }
   ],
   "source": [
    "lr = WordNetLemmatizer()\n",
    "corpus = []\n",
    "for i in range(0, len(messages)):\n",
    "    print(\"Status: %s / %s\" %(i, len(messages)), end=\"\\r\")\n",
    "    review = re.sub('[^a-zA-Z]', ' ', messages['text'][i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    \n",
    "    review = [lr.lemmatize(word) for word in review if not word in stopwords.words('english')]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'house dem aide even see comey letter jason chaffetz tweeted darrell lucus october subscribe jason chaffetz stump american fork utah image courtesy michael jolley available creative common license apology keith olbermann doubt worst person world week fbi director james comey according house democratic aide look like also know second worst person well turn comey sent infamous letter announcing fbi looking email may related hillary clinton email server ranking democrat relevant committee hear comey found via tweet one republican committee chairman know comey notified republican chairman democratic ranking member house intelligence judiciary oversight committee agency reviewing email recently discovered order see contained classified information long letter went oversight committee chairman jason chaffetz set political world ablaze tweet fbi dir informed fbi learned existence email appear pertinent investigation case reopened jason chaffetz jasoninthehouse october course know case comey actually saying reviewing email light unrelated case know anthony weiner sexting teenager apparently little thing fact matter chaffetz utah republican already vowed initiate raft investigation hillary win least two year worth possibly entire term worth apparently chaffetz thought fbi already work resulting tweet briefly roiled nation cooler head realized dud according senior house democratic aide misreading letter may least chaffetz sin aide told shareblue bos democrat even know comey letter time found checked twitter democratic ranking member relevant committee receive comey letter republican chairman fact democratic ranking member receive chairman oversight government reform committee jason chaffetz tweeted made public let see got right fbi director tell chaffetz gop committee chairman major development potentially politically explosive investigation neither chaffetz colleague courtesy let democratic counterpart know instead according aide made find twitter already talk daily ko comey provided advance notice letter chaffetz republican giving time turn spin machine may make good theater nothing far even suggests case nothing far suggests comey anything grossly incompetent tone deaf suggest however chaffetz acting way make dan burton darrell issa look like model responsibility bipartisanship even decency notify ranking member elijah cummings something explosive trample basic standard fairness know granted likely chaffetz answer sits ridiculously republican district anchored provo orem cook partisan voting index r gave mitt romney punishing percent vote moreover republican house leadership given full support chaffetz planned fishing expedition mean turn hot light textbook example house become republican control also second worst person world darrell lucus darrell something graduate university north carolina considers journalist old school attempt turn member religious right college succeeded turning religious right worst nightmare charismatic christian unapologetic liberal desire stand scared silence increased survived abusive three year marriage may know daily ko christian dem nc follow twitter darrelllucus connect facebook click buy darrell mello yello connect'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_title, X_test_title, y_train_title, y_test_title = train_test_split(corpus, y, test_size = 0.2, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "max_vocab_title = 1500\n",
    "\n",
    "# Create TF-IDF of title\n",
    "tfidf_title = TfidfVectorizer(stop_words=stopwords.words('english'),ngram_range=(1,3), max_features=max_vocab_title)\n",
    "\n",
    "sparse_tfidf_train_title = tfidf_title.fit_transform(X_train_title)\n",
    "\n",
    "X_tfidf_train_title = sparse_tfidf_train_title.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 64)                96064     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 17        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 97,121\n",
      "Trainable params: 97,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "59/59 [==============================] - 4s 71ms/step - loss: 0.6473 - accuracy: 0.7210 - recall: 0.8704 - val_loss: 0.5683 - val_accuracy: 0.8325 - val_recall: 0.9718\n",
      "Epoch 2/10\n",
      "59/59 [==============================] - 1s 9ms/step - loss: 0.5240 - accuracy: 0.8833 - recall: 0.9643 - val_loss: 0.4966 - val_accuracy: 0.9132 - val_recall: 0.9477\n",
      "Epoch 3/10\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.4781 - accuracy: 0.9284 - recall: 0.9575 - val_loss: 0.4784 - val_accuracy: 0.9269 - val_recall: 0.9461\n",
      "Epoch 4/10\n",
      "59/59 [==============================] - 1s 11ms/step - loss: 0.4610 - accuracy: 0.9438 - recall: 0.9579 - val_loss: 0.4786 - val_accuracy: 0.9224 - val_recall: 0.9565\n",
      "Epoch 5/10\n",
      "59/59 [==============================] - 1s 14ms/step - loss: 0.4461 - accuracy: 0.9539 - recall: 0.9624 - val_loss: 0.4732 - val_accuracy: 0.9316 - val_recall: 0.9477\n",
      "Epoch 6/10\n",
      "59/59 [==============================] - 1s 9ms/step - loss: 0.4375 - accuracy: 0.9599 - recall: 0.9633 - val_loss: 0.4735 - val_accuracy: 0.9340 - val_recall: 0.9444\n",
      "Epoch 7/10\n",
      "59/59 [==============================] - 1s 14ms/step - loss: 0.4312 - accuracy: 0.9651 - recall: 0.9620 - val_loss: 0.4805 - val_accuracy: 0.9313 - val_recall: 0.9452\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x37333908>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_title = tf.keras.Sequential()\n",
    "model_title.add(tf.keras.layers.Dense(64,input_shape=(max_vocab_title,),activation='relu'))\n",
    "model_title.add(tf.keras.layers.Dropout(0.2))\n",
    "model_title.add(tf.keras.layers.Dense(16,activation='relu'))\n",
    "model_title.add(tf.keras.layers.Dropout(0.2))\n",
    "model_title.add(tf.keras.layers.Dense(1,activation='relu'))\n",
    "model_title.add(tf.keras.layers.Activation('sigmoid'))\n",
    "model_title.summary()\n",
    "model_title.compile(loss='binary_crossentropy', optimizer='adam', metrics = ['accuracy', 'Recall'])\n",
    "\n",
    "batch_size = 200\n",
    "max_epochs = 10\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(patience=2)\n",
    "\n",
    "model_title.fit(X_tfidf_train_title, y_train_title, batch_size = batch_size, epochs = max_epochs, callbacks=[early_stopping], validation_split = 0.2 , shuffle=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_tfidf_test_title = tfidf_title.transform(X_test_title)\n",
    "\n",
    "X_tfidf_test_title = sparse_tfidf_test_title.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115/115 [==============================] - 0s 2ms/step - loss: 0.4853 - accuracy: 0.9314 - recall: 0.9481\n"
     ]
    }
   ],
   "source": [
    "model_title_loss, model_title_accuracy, model_title_recall = model_title.evaluate(X_tfidf_test_title, y_test_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4853349030017853, 0.9313644766807556, 0.9481340646743774)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_title_loss, model_title_accuracy, model_title_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_title.save('rnn_text_tfidf.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "pickle.dump(tfidf_title, open('tranform_text.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
